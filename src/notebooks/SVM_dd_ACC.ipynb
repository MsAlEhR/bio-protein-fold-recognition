{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training SVM classifier on DD_ACC dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to read dataset from CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "#dd_dataset = pd.read_csv('./dataset/dd_pssm_dataset_improved.csv')\n",
    "# Add separated dimers feature extraction\n",
    "\n",
    "dd_dataset = pd.read_csv('../dataset/ACC_dataset_IG.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Protein name</th>\n",
       "      <th>F977</th>\n",
       "      <th>F912</th>\n",
       "      <th>F1166</th>\n",
       "      <th>F647</th>\n",
       "      <th>F793</th>\n",
       "      <th>F708</th>\n",
       "      <th>F996</th>\n",
       "      <th>F898</th>\n",
       "      <th>...</th>\n",
       "      <th>F790</th>\n",
       "      <th>F1340</th>\n",
       "      <th>F1540</th>\n",
       "      <th>F1169</th>\n",
       "      <th>F305</th>\n",
       "      <th>F1507</th>\n",
       "      <th>F1299</th>\n",
       "      <th>F1155</th>\n",
       "      <th>F386</th>\n",
       "      <th>F1221</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Globm-like(alpha)</td>\n",
       "      <td>2LHB</td>\n",
       "      <td>-0.399737</td>\n",
       "      <td>0.405657</td>\n",
       "      <td>0.485693</td>\n",
       "      <td>-0.093024</td>\n",
       "      <td>0.072585</td>\n",
       "      <td>-0.720872</td>\n",
       "      <td>0.707496</td>\n",
       "      <td>0.320963</td>\n",
       "      <td>...</td>\n",
       "      <td>1.062513</td>\n",
       "      <td>-0.168908</td>\n",
       "      <td>0.988832</td>\n",
       "      <td>0.606575</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>1.804784e-01</td>\n",
       "      <td>-0.483699</td>\n",
       "      <td>0.005991</td>\n",
       "      <td>3.151907e-01</td>\n",
       "      <td>-3.097699e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Globm-like(alpha)</td>\n",
       "      <td>3SDHA</td>\n",
       "      <td>-0.137876</td>\n",
       "      <td>-0.107061</td>\n",
       "      <td>-0.345996</td>\n",
       "      <td>0.175331</td>\n",
       "      <td>-0.437490</td>\n",
       "      <td>0.396697</td>\n",
       "      <td>-0.214693</td>\n",
       "      <td>0.708716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594735</td>\n",
       "      <td>-0.151556</td>\n",
       "      <td>0.353050</td>\n",
       "      <td>-0.111828</td>\n",
       "      <td>0.003111</td>\n",
       "      <td>-5.939943e-02</td>\n",
       "      <td>-0.403252</td>\n",
       "      <td>-0.172528</td>\n",
       "      <td>-4.417598e-02</td>\n",
       "      <td>2.201761e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Globm-like(alpha)</td>\n",
       "      <td>1FLP</td>\n",
       "      <td>-0.025017</td>\n",
       "      <td>-0.146573</td>\n",
       "      <td>-0.098038</td>\n",
       "      <td>-0.095989</td>\n",
       "      <td>-0.101436</td>\n",
       "      <td>-0.250592</td>\n",
       "      <td>-0.143614</td>\n",
       "      <td>-0.117110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025293</td>\n",
       "      <td>0.195421</td>\n",
       "      <td>-0.116406</td>\n",
       "      <td>0.047839</td>\n",
       "      <td>0.176857</td>\n",
       "      <td>-2.134016e-02</td>\n",
       "      <td>0.112846</td>\n",
       "      <td>0.190956</td>\n",
       "      <td>-1.051678e-02</td>\n",
       "      <td>-5.154598e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Globm-like(alpha)</td>\n",
       "      <td>2HBG</td>\n",
       "      <td>0.139929</td>\n",
       "      <td>0.009713</td>\n",
       "      <td>0.009357</td>\n",
       "      <td>-0.056709</td>\n",
       "      <td>-0.227964</td>\n",
       "      <td>-0.093643</td>\n",
       "      <td>-0.175371</td>\n",
       "      <td>0.252061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.477308</td>\n",
       "      <td>0.370757</td>\n",
       "      <td>0.188255</td>\n",
       "      <td>-0.461226</td>\n",
       "      <td>-0.014985</td>\n",
       "      <td>-2.483331e-02</td>\n",
       "      <td>-0.086637</td>\n",
       "      <td>-0.026254</td>\n",
       "      <td>-5.159578e-03</td>\n",
       "      <td>-6.422533e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Globm-like(alpha)</td>\n",
       "      <td>2MGE</td>\n",
       "      <td>-0.574369</td>\n",
       "      <td>0.316517</td>\n",
       "      <td>0.304017</td>\n",
       "      <td>0.476801</td>\n",
       "      <td>-0.527676</td>\n",
       "      <td>0.360491</td>\n",
       "      <td>1.439641</td>\n",
       "      <td>-0.497493</td>\n",
       "      <td>...</td>\n",
       "      <td>1.006694</td>\n",
       "      <td>-0.669374</td>\n",
       "      <td>-0.001340</td>\n",
       "      <td>-0.533603</td>\n",
       "      <td>-0.065659</td>\n",
       "      <td>1.346238e-16</td>\n",
       "      <td>-0.283534</td>\n",
       "      <td>-0.047445</td>\n",
       "      <td>4.457609e-17</td>\n",
       "      <td>3.963891e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 502 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Fold Protein name      F977      F912     F1166      F647  \\\n",
       "0  Globm-like(alpha)         2LHB -0.399737  0.405657  0.485693 -0.093024   \n",
       "1  Globm-like(alpha)        3SDHA -0.137876 -0.107061 -0.345996  0.175331   \n",
       "2  Globm-like(alpha)         1FLP -0.025017 -0.146573 -0.098038 -0.095989   \n",
       "3  Globm-like(alpha)         2HBG  0.139929  0.009713  0.009357 -0.056709   \n",
       "4  Globm-like(alpha)         2MGE -0.574369  0.316517  0.304017  0.476801   \n",
       "\n",
       "       F793      F708      F996      F898      ...           F790     F1340  \\\n",
       "0  0.072585 -0.720872  0.707496  0.320963      ...       1.062513 -0.168908   \n",
       "1 -0.437490  0.396697 -0.214693  0.708716      ...       0.594735 -0.151556   \n",
       "2 -0.101436 -0.250592 -0.143614 -0.117110      ...      -0.025293  0.195421   \n",
       "3 -0.227964 -0.093643 -0.175371  0.252061      ...       0.477308  0.370757   \n",
       "4 -0.527676  0.360491  1.439641 -0.497493      ...       1.006694 -0.669374   \n",
       "\n",
       "      F1540     F1169      F305         F1507     F1299     F1155  \\\n",
       "0  0.988832  0.606575  0.005033  1.804784e-01 -0.483699  0.005991   \n",
       "1  0.353050 -0.111828  0.003111 -5.939943e-02 -0.403252 -0.172528   \n",
       "2 -0.116406  0.047839  0.176857 -2.134016e-02  0.112846  0.190956   \n",
       "3  0.188255 -0.461226 -0.014985 -2.483331e-02 -0.086637 -0.026254   \n",
       "4 -0.001340 -0.533603 -0.065659  1.346238e-16 -0.283534 -0.047445   \n",
       "\n",
       "           F386         F1221  \n",
       "0  3.151907e-01 -3.097699e-01  \n",
       "1 -4.417598e-02  2.201761e-01  \n",
       "2 -1.051678e-02 -5.154598e-02  \n",
       "3 -5.159578e-03 -6.422533e-02  \n",
       "4  4.457609e-17  3.963891e-16  \n",
       "\n",
       "[5 rows x 502 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert class lables to unique integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode class labels\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "y_true, labels = pd.factorize(dd_dataset.Fold)\n",
    "dd_dataset.insert(1, 'class labels', y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>class labels</th>\n",
       "      <th>Protein name</th>\n",
       "      <th>F977</th>\n",
       "      <th>F912</th>\n",
       "      <th>F1166</th>\n",
       "      <th>F647</th>\n",
       "      <th>F793</th>\n",
       "      <th>F708</th>\n",
       "      <th>F996</th>\n",
       "      <th>...</th>\n",
       "      <th>F790</th>\n",
       "      <th>F1340</th>\n",
       "      <th>F1540</th>\n",
       "      <th>F1169</th>\n",
       "      <th>F305</th>\n",
       "      <th>F1507</th>\n",
       "      <th>F1299</th>\n",
       "      <th>F1155</th>\n",
       "      <th>F386</th>\n",
       "      <th>F1221</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Globm-like(alpha)</td>\n",
       "      <td>0</td>\n",
       "      <td>2LHB</td>\n",
       "      <td>-0.399737</td>\n",
       "      <td>0.405657</td>\n",
       "      <td>0.485693</td>\n",
       "      <td>-0.093024</td>\n",
       "      <td>0.072585</td>\n",
       "      <td>-0.720872</td>\n",
       "      <td>0.707496</td>\n",
       "      <td>...</td>\n",
       "      <td>1.062513</td>\n",
       "      <td>-0.168908</td>\n",
       "      <td>0.988832</td>\n",
       "      <td>0.606575</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>1.804784e-01</td>\n",
       "      <td>-0.483699</td>\n",
       "      <td>0.005991</td>\n",
       "      <td>3.151907e-01</td>\n",
       "      <td>-3.097699e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Globm-like(alpha)</td>\n",
       "      <td>0</td>\n",
       "      <td>3SDHA</td>\n",
       "      <td>-0.137876</td>\n",
       "      <td>-0.107061</td>\n",
       "      <td>-0.345996</td>\n",
       "      <td>0.175331</td>\n",
       "      <td>-0.437490</td>\n",
       "      <td>0.396697</td>\n",
       "      <td>-0.214693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594735</td>\n",
       "      <td>-0.151556</td>\n",
       "      <td>0.353050</td>\n",
       "      <td>-0.111828</td>\n",
       "      <td>0.003111</td>\n",
       "      <td>-5.939943e-02</td>\n",
       "      <td>-0.403252</td>\n",
       "      <td>-0.172528</td>\n",
       "      <td>-4.417598e-02</td>\n",
       "      <td>2.201761e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Globm-like(alpha)</td>\n",
       "      <td>0</td>\n",
       "      <td>1FLP</td>\n",
       "      <td>-0.025017</td>\n",
       "      <td>-0.146573</td>\n",
       "      <td>-0.098038</td>\n",
       "      <td>-0.095989</td>\n",
       "      <td>-0.101436</td>\n",
       "      <td>-0.250592</td>\n",
       "      <td>-0.143614</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025293</td>\n",
       "      <td>0.195421</td>\n",
       "      <td>-0.116406</td>\n",
       "      <td>0.047839</td>\n",
       "      <td>0.176857</td>\n",
       "      <td>-2.134016e-02</td>\n",
       "      <td>0.112846</td>\n",
       "      <td>0.190956</td>\n",
       "      <td>-1.051678e-02</td>\n",
       "      <td>-5.154598e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Globm-like(alpha)</td>\n",
       "      <td>0</td>\n",
       "      <td>2HBG</td>\n",
       "      <td>0.139929</td>\n",
       "      <td>0.009713</td>\n",
       "      <td>0.009357</td>\n",
       "      <td>-0.056709</td>\n",
       "      <td>-0.227964</td>\n",
       "      <td>-0.093643</td>\n",
       "      <td>-0.175371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.477308</td>\n",
       "      <td>0.370757</td>\n",
       "      <td>0.188255</td>\n",
       "      <td>-0.461226</td>\n",
       "      <td>-0.014985</td>\n",
       "      <td>-2.483331e-02</td>\n",
       "      <td>-0.086637</td>\n",
       "      <td>-0.026254</td>\n",
       "      <td>-5.159578e-03</td>\n",
       "      <td>-6.422533e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Globm-like(alpha)</td>\n",
       "      <td>0</td>\n",
       "      <td>2MGE</td>\n",
       "      <td>-0.574369</td>\n",
       "      <td>0.316517</td>\n",
       "      <td>0.304017</td>\n",
       "      <td>0.476801</td>\n",
       "      <td>-0.527676</td>\n",
       "      <td>0.360491</td>\n",
       "      <td>1.439641</td>\n",
       "      <td>...</td>\n",
       "      <td>1.006694</td>\n",
       "      <td>-0.669374</td>\n",
       "      <td>-0.001340</td>\n",
       "      <td>-0.533603</td>\n",
       "      <td>-0.065659</td>\n",
       "      <td>1.346238e-16</td>\n",
       "      <td>-0.283534</td>\n",
       "      <td>-0.047445</td>\n",
       "      <td>4.457609e-17</td>\n",
       "      <td>3.963891e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 503 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Fold  class labels Protein name      F977      F912     F1166  \\\n",
       "0  Globm-like(alpha)             0         2LHB -0.399737  0.405657  0.485693   \n",
       "1  Globm-like(alpha)             0        3SDHA -0.137876 -0.107061 -0.345996   \n",
       "2  Globm-like(alpha)             0         1FLP -0.025017 -0.146573 -0.098038   \n",
       "3  Globm-like(alpha)             0         2HBG  0.139929  0.009713  0.009357   \n",
       "4  Globm-like(alpha)             0         2MGE -0.574369  0.316517  0.304017   \n",
       "\n",
       "       F647      F793      F708      F996      ...           F790     F1340  \\\n",
       "0 -0.093024  0.072585 -0.720872  0.707496      ...       1.062513 -0.168908   \n",
       "1  0.175331 -0.437490  0.396697 -0.214693      ...       0.594735 -0.151556   \n",
       "2 -0.095989 -0.101436 -0.250592 -0.143614      ...      -0.025293  0.195421   \n",
       "3 -0.056709 -0.227964 -0.093643 -0.175371      ...       0.477308  0.370757   \n",
       "4  0.476801 -0.527676  0.360491  1.439641      ...       1.006694 -0.669374   \n",
       "\n",
       "      F1540     F1169      F305         F1507     F1299     F1155  \\\n",
       "0  0.988832  0.606575  0.005033  1.804784e-01 -0.483699  0.005991   \n",
       "1  0.353050 -0.111828  0.003111 -5.939943e-02 -0.403252 -0.172528   \n",
       "2 -0.116406  0.047839  0.176857 -2.134016e-02  0.112846  0.190956   \n",
       "3  0.188255 -0.461226 -0.014985 -2.483331e-02 -0.086637 -0.026254   \n",
       "4 -0.001340 -0.533603 -0.065659  1.346238e-16 -0.283534 -0.047445   \n",
       "\n",
       "           F386         F1221  \n",
       "0  3.151907e-01 -3.097699e-01  \n",
       "1 -4.417598e-02  2.201761e-01  \n",
       "2 -1.051678e-02 -5.154598e-02  \n",
       "3 -5.159578e-03 -6.422533e-02  \n",
       "4  4.457609e-17  3.963891e-16  \n",
       "\n",
       "[5 rows x 503 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a training set from pandas data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 311, Number of features: 500\n"
     ]
    }
   ],
   "source": [
    "train_data = dd_dataset.iloc[:,3:].values\n",
    "\n",
    "# Normalize dataset\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "train_scaled = min_max_scaler.fit_transform(train_data)\n",
    "train_data = train_scaled\n",
    "\n",
    "print(\"Number of samples: %d, Number of features: %d\" % (train_data.shape[0], train_data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.259159</td>\n",
       "      <td>0.575966</td>\n",
       "      <td>0.563149</td>\n",
       "      <td>0.467414</td>\n",
       "      <td>0.484902</td>\n",
       "      <td>0.143481</td>\n",
       "      <td>0.693966</td>\n",
       "      <td>0.435396</td>\n",
       "      <td>0.543338</td>\n",
       "      <td>0.348305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.762921</td>\n",
       "      <td>0.349028</td>\n",
       "      <td>0.697582</td>\n",
       "      <td>0.539319</td>\n",
       "      <td>0.338390</td>\n",
       "      <td>0.407979</td>\n",
       "      <td>0.208221</td>\n",
       "      <td>0.459416</td>\n",
       "      <td>0.500133</td>\n",
       "      <td>0.215216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.342424</td>\n",
       "      <td>0.414306</td>\n",
       "      <td>0.303531</td>\n",
       "      <td>0.570877</td>\n",
       "      <td>0.331796</td>\n",
       "      <td>0.544585</td>\n",
       "      <td>0.410079</td>\n",
       "      <td>0.535519</td>\n",
       "      <td>0.529921</td>\n",
       "      <td>0.007575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.601383</td>\n",
       "      <td>0.353459</td>\n",
       "      <td>0.539792</td>\n",
       "      <td>0.362631</td>\n",
       "      <td>0.337849</td>\n",
       "      <td>0.331345</td>\n",
       "      <td>0.232597</td>\n",
       "      <td>0.384014</td>\n",
       "      <td>0.394994</td>\n",
       "      <td>0.367936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.378311</td>\n",
       "      <td>0.401848</td>\n",
       "      <td>0.380933</td>\n",
       "      <td>0.466271</td>\n",
       "      <td>0.432667</td>\n",
       "      <td>0.312268</td>\n",
       "      <td>0.431960</td>\n",
       "      <td>0.322280</td>\n",
       "      <td>0.376448</td>\n",
       "      <td>0.398974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387269</td>\n",
       "      <td>0.442076</td>\n",
       "      <td>0.423282</td>\n",
       "      <td>0.401901</td>\n",
       "      <td>0.386746</td>\n",
       "      <td>0.343504</td>\n",
       "      <td>0.388979</td>\n",
       "      <td>0.537541</td>\n",
       "      <td>0.404841</td>\n",
       "      <td>0.289631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.430759</td>\n",
       "      <td>0.451125</td>\n",
       "      <td>0.414457</td>\n",
       "      <td>0.481415</td>\n",
       "      <td>0.394688</td>\n",
       "      <td>0.368598</td>\n",
       "      <td>0.422184</td>\n",
       "      <td>0.417605</td>\n",
       "      <td>0.387447</td>\n",
       "      <td>0.484352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560832</td>\n",
       "      <td>0.486857</td>\n",
       "      <td>0.498893</td>\n",
       "      <td>0.276699</td>\n",
       "      <td>0.332756</td>\n",
       "      <td>0.342388</td>\n",
       "      <td>0.328534</td>\n",
       "      <td>0.445797</td>\n",
       "      <td>0.406409</td>\n",
       "      <td>0.285977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.203631</td>\n",
       "      <td>0.547860</td>\n",
       "      <td>0.506437</td>\n",
       "      <td>0.687109</td>\n",
       "      <td>0.304725</td>\n",
       "      <td>0.531591</td>\n",
       "      <td>0.919349</td>\n",
       "      <td>0.224060</td>\n",
       "      <td>0.370848</td>\n",
       "      <td>0.395755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743645</td>\n",
       "      <td>0.221210</td>\n",
       "      <td>0.451839</td>\n",
       "      <td>0.258898</td>\n",
       "      <td>0.318495</td>\n",
       "      <td>0.350321</td>\n",
       "      <td>0.268873</td>\n",
       "      <td>0.436846</td>\n",
       "      <td>0.407918</td>\n",
       "      <td>0.304485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.259159  0.575966  0.563149  0.467414  0.484902  0.143481  0.693966   \n",
       "1  0.342424  0.414306  0.303531  0.570877  0.331796  0.544585  0.410079   \n",
       "2  0.378311  0.401848  0.380933  0.466271  0.432667  0.312268  0.431960   \n",
       "3  0.430759  0.451125  0.414457  0.481415  0.394688  0.368598  0.422184   \n",
       "4  0.203631  0.547860  0.506437  0.687109  0.304725  0.531591  0.919349   \n",
       "\n",
       "        7         8         9      ...          490       491       492  \\\n",
       "0  0.435396  0.543338  0.348305    ...     0.762921  0.349028  0.697582   \n",
       "1  0.535519  0.529921  0.007575    ...     0.601383  0.353459  0.539792   \n",
       "2  0.322280  0.376448  0.398974    ...     0.387269  0.442076  0.423282   \n",
       "3  0.417605  0.387447  0.484352    ...     0.560832  0.486857  0.498893   \n",
       "4  0.224060  0.370848  0.395755    ...     0.743645  0.221210  0.451839   \n",
       "\n",
       "        493       494       495       496       497       498       499  \n",
       "0  0.539319  0.338390  0.407979  0.208221  0.459416  0.500133  0.215216  \n",
       "1  0.362631  0.337849  0.331345  0.232597  0.384014  0.394994  0.367936  \n",
       "2  0.401901  0.386746  0.343504  0.388979  0.537541  0.404841  0.289631  \n",
       "3  0.276699  0.332756  0.342388  0.328534  0.445797  0.406409  0.285977  \n",
       "4  0.258898  0.318495  0.350321  0.268873  0.436846  0.407918  0.304485  \n",
       "\n",
       "[5 rows x 500 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show normlaized data\n",
    "\n",
    "train = pd.DataFrame(train_data)\n",
    "\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Frequency of folds\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "freq_plot = dd_dataset['Fold'].value_counts().plot(ax=ax, kind='bar')\n",
    "freq_plot.set_ylabel('Number of proteins')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Hyperparameters\n",
    "kernel = 'rbf'\n",
    "\n",
    "# An instance of SVM classifier\n",
    "svm_cl = SVC(kernel=kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define range of parameters for Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Penalty parameter\n",
    "c_range = {'C': [float(2**i) for i in range(-14, 14)]}\n",
    "# Gamma parameter for RBF kernel\n",
    "gamma_range = {'gamma': [float(2**i) for i in range(-14, 14)]} if kernel == 'rbf' else {}\n",
    "\n",
    "param_range = {**c_range, **gamma_range}\n",
    "\n",
    "# Arguments for grid search\n",
    "cv_fold = 10\n",
    "n_workers = -1 # Number of CPU threads\n",
    "\n",
    "result = GridSearchCV(svm_cl, param_range, cv=cv_fold, n_jobs=n_workers, refit=True,\n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start grid search!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 784 candidates, totalling 7840 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mir\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 6 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:   44.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4992 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6042 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 7192 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 7840 out of 7840 | elapsed:  5.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'C': [6.103515625e-05, 0.0001220703125, 0.000244140625, 0.00048828125, 0.0009765625, 0.001953125, 0.00390625, 0.0078125, 0.015625, 0.03125, 0.0625, 0.125, 0.25, 0.5, 1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0, 128.0, 256.0, 512.0, 1024.0, 2048.0, 4096.0, 8192.0], 'gamma': [6.103515625e-05, 0.0...25, 0.5, 1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0, 128.0, 256.0, 512.0, 1024.0, 2048.0, 4096.0, 8192.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.fit(train_data, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 22.83\n"
     ]
    }
   ],
   "source": [
    "print(\"Best accuracy: %.2f\" % (result.best_score_ * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  90.9967845659164\n"
     ]
    }
   ],
   "source": [
    "#from misc import plt_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "y_pred = result.best_estimator_.predict(train_data)\n",
    "\n",
    "cm = confusion_matrix(labels[y_true], labels[y_pred])\n",
    "\n",
    "print(\"Accuracy: \", (accuracy_score(labels[y_true], labels[y_pred]) * 100))\n",
    "\n",
    "#plt.figure(figsize=(20, 15))\n",
    "#plt_confusion_matrix(cm, np.unique(labels[y_true]))\n",
    "#plt.savefig(\"./report/DD_confusion_matrix.png\", dpi=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                    (TIM)-BARREL (ALPHA/BELTA)       1.00      0.83      0.91        29\n",
      "                   4-HELICAL CYTOKINES (ALPHA)       1.00      0.89      0.94         9\n",
      "                  4-HELICAL UP-AND-DOWN BUNDLE       1.00      1.00      1.00         7\n",
      "                        ALPHA: EF-HAND (ALPHA)       1.00      1.00      1.00         6\n",
      "                     BELTA-GRASP (ALPHA+BELTA)       1.00      1.00      1.00         7\n",
      "         CONA-LIKE LECTINGS/GLUCANASES (BELTA)       1.00      1.00      1.00         7\n",
      "                           CUPREDOXINS (BELTA)       1.00      1.00      1.00         9\n",
      "                          CYTOCHROME C (ALPHA)       1.00      1.00      1.00         7\n",
      "           DNA-BINDING 3-HELICALBUNDLE (ALPHA)       1.00      1.00      1.00        12\n",
      "   FAD (ALSO NAD) -BINDING MOTIF (ALPHA/BELTA)       0.28      1.00      0.44        11\n",
      "                 FERREDOXIN-LIKE (ALPHA+BELTA)       1.00      0.85      0.92        13\n",
      "                 FLAVODOXIN-LIKE (ALPHA/BELTA)       1.00      1.00      1.00        11\n",
      "                             Globm-like(alpha)       1.00      1.00      1.00        13\n",
      "                      HYDROLASES (ALPHA/BELTA)       1.00      1.00      1.00        11\n",
      "    IMMUNOGLOBULIN-LIKE BELTA-SANDWICH (BELTA)       1.00      0.87      0.93        30\n",
      "                            LIPOCALINS (BELTA)       1.00      1.00      1.00         9\n",
      "    NAD(P)-BINDING ROSSMANN-FOLD (ALPHA/BELTA)       1.00      0.77      0.87        13\n",
      "                               OB-FOLD (BELTA)       1.00      0.85      0.92        13\n",
      "    P-LOOP CONTAINING NUCLEOTIDE (ALPHA/BELTA)       1.00      0.70      0.82        10\n",
      "PERIPLASMIC BINDING PROTEIN-LIKE (ALPHA/BELTA)       1.00      0.91      0.95        11\n",
      "       RIBONUCLEASE H-LIKE MOTIF (ALPHA/BELTA)       1.00      1.00      1.00        10\n",
      "                       SH3 LIKE BARREL (BELTA)       1.00      1.00      1.00         8\n",
      "SMALL INHIBITORS TOXINS, LECTINS (ALPHA+BELTA)       1.00      1.00      1.00        13\n",
      "                THIOREDOXIN-LIKE (ALPHA/BELTA)       1.00      0.67      0.80         9\n",
      "                               TREFOIL (BELTA)       1.00      1.00      1.00         8\n",
      "         TRYPSIN-LIKE SERINE PROTEASES (BELTA)       1.00      0.89      0.94         9\n",
      "        VIRAL COAT AND CAPSID PROTEINS (BELTA)       1.00      0.81      0.90        16\n",
      "\n",
      "                                   avg / total       0.97      0.91      0.93       311\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels[y_true], labels[y_pred]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Create Dmatrix for more performance \n",
    "data_matrix = xgb.DMatrix(data=train_data,label=labels)\n",
    "\n",
    "# Split data to train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, labels, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantitate an XGBosst Classifier\n",
    "xg_clf = xgb.XGBClassifier(objective ='binary:logistic', colsample_bytree = 0.1, learning_rate = 0.1,\n",
    "                max_depth = 10, alpha = 10, n_estimators = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit the classifier to the training set\n",
    "xg_clf.fit(X_train,y_train)\n",
    "\n",
    "# Predit test data\n",
    "preds = xg_clf.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Best accuracy: %.2f\" % (accuracy*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
